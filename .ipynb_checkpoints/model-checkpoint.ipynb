{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efcd9058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "091db69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_fwf(\"pride_book.txt\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ea7d237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Project Gutenberg eBook of Pride and preju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This eBook is for the use of anyone anywhere i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>most other parts of the world at no cost and w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whatsoever. You may copy it, give it away or r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of the Project Gutenberg License included with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  The Project Gutenberg eBook of Pride and preju...\n",
       "1  This eBook is for the use of anyone anywhere i...\n",
       "2  most other parts of the world at no cost and w...\n",
       "3  whatsoever. You may copy it, give it away or r...\n",
       "4  of the Project Gutenberg License included with..."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd96ec04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11886, 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d072904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bd63dba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The Project Gutenberg eBook of Pride and prejudice, by Jane Austen',\n",
       "       'This eBook is for the use of anyone anywhere in the United States and',\n",
       "       'most other parts of the world at no cost and with almost no restrictions',\n",
       "       'whatsoever. You may copy it, give it away or re-use it under the terms',\n",
       "       'of the Project Gutenberg License included with this eBook or online at'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2f3f61cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(oov_token=\"nothing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c7258047",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "049549df",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e347eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tokenizer.texts_to_sequences(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ea37bf22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 183, 164, 1031, 4, 306, 5, 976, 31, 74, 727],\n",
       " [43, 1031, 25, 23, 2, 516, 4, 561, 2717, 8, 2, 702, 780, 5],\n",
       " [96, 81, 1454, 4, 2, 219, 27, 44, 1614, 5, 22, 248, 44, 2718],\n",
       " [3365, 16, 90, 1092, 14, 135, 14, 141, 53, 1809, 516, 14, 390, 2, 379],\n",
       " [4, 2, 183, 164, 809, 2013, 22, 43, 1031, 53, 2014, 27]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "12504f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11886"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e8620b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 183],\n",
       " [183, 164],\n",
       " [164, 1031],\n",
       " [1031, 4],\n",
       " [4, 306],\n",
       " [306, 5],\n",
       " [5, 976],\n",
       " [976, 31],\n",
       " [31, 74],\n",
       " [74, 727]]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating list of all pairs\n",
    "x_list=[]\n",
    "for i in x[:len(x)//2]:\n",
    "    l=len(i)\n",
    "    for j in range(l-1):\n",
    "        x_list.append([i[j],i[j+1]])\n",
    "x_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b756bd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59853"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5e25ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_set=[i[0] for i in x_list]\n",
    "y_set=[i[1] for i in x_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ec148ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 183, 164, 1031, 4]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_set[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2dfcc0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[183, 164, 1031, 4, 306]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_set[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e3159336",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocal_size=len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "547a66b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_set=to_categorical(y_set, num_classes=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9e273374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6d7ddf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.Sequential([\n",
    "    layers.Embedding(8000,10,input_length=1),\n",
    "    layers.LSTM(50),\n",
    "    layers.Dense(8000, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4f69faa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 1, 10)             80000     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 50)                12200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8000)              408000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 500200 (1.91 MB)\n",
      "Trainable params: 500200 (1.91 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "33869980",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e9e0ca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_set=np.array(x_set)\n",
    "y_set=np.array(y_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f605b766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1871/1871 [==============================] - 35s 18ms/step - loss: 5.4516 - accuracy: 0.1052\n",
      "Epoch 2/100\n",
      "1871/1871 [==============================] - 38s 21ms/step - loss: 5.3203 - accuracy: 0.1186\n",
      "Epoch 3/100\n",
      "1871/1871 [==============================] - 49s 26ms/step - loss: 5.2172 - accuracy: 0.1291\n",
      "Epoch 4/100\n",
      "1871/1871 [==============================] - 45s 24ms/step - loss: 5.1239 - accuracy: 0.1377\n",
      "Epoch 5/100\n",
      "1871/1871 [==============================] - 47s 25ms/step - loss: 5.0402 - accuracy: 0.1442\n",
      "Epoch 6/100\n",
      "1871/1871 [==============================] - 44s 23ms/step - loss: 4.9658 - accuracy: 0.1532\n",
      "Epoch 7/100\n",
      "1871/1871 [==============================] - 33s 17ms/step - loss: 4.9005 - accuracy: 0.1599\n",
      "Epoch 8/100\n",
      "1871/1871 [==============================] - 40s 21ms/step - loss: 4.8421 - accuracy: 0.1645\n",
      "Epoch 9/100\n",
      "1871/1871 [==============================] - 45s 24ms/step - loss: 4.7897 - accuracy: 0.1687\n",
      "Epoch 10/100\n",
      "1871/1871 [==============================] - 32s 17ms/step - loss: 4.7414 - accuracy: 0.1716\n",
      "Epoch 11/100\n",
      "1871/1871 [==============================] - 33s 18ms/step - loss: 4.6964 - accuracy: 0.1742\n",
      "Epoch 12/100\n",
      "1871/1871 [==============================] - 35s 19ms/step - loss: 4.6547 - accuracy: 0.1757\n",
      "Epoch 13/100\n",
      "1871/1871 [==============================] - 38s 20ms/step - loss: 4.6162 - accuracy: 0.1781\n",
      "Epoch 14/100\n",
      "1871/1871 [==============================] - 43s 23ms/step - loss: 4.5801 - accuracy: 0.1816\n",
      "Epoch 15/100\n",
      "1871/1871 [==============================] - 47s 25ms/step - loss: 4.5460 - accuracy: 0.1833\n",
      "Epoch 16/100\n",
      "1871/1871 [==============================] - 47s 25ms/step - loss: 4.5144 - accuracy: 0.1837\n",
      "Epoch 17/100\n",
      "1871/1871 [==============================] - 47s 25ms/step - loss: 4.4842 - accuracy: 0.1860\n",
      "Epoch 18/100\n",
      "1871/1871 [==============================] - 35s 19ms/step - loss: 4.4548 - accuracy: 0.1877\n",
      "Epoch 19/100\n",
      "1871/1871 [==============================] - 34s 18ms/step - loss: 4.4282 - accuracy: 0.1891\n",
      "Epoch 20/100\n",
      "1871/1871 [==============================] - 36s 19ms/step - loss: 4.4023 - accuracy: 0.1912\n",
      "Epoch 21/100\n",
      "1871/1871 [==============================] - 38s 21ms/step - loss: 4.3784 - accuracy: 0.1918\n",
      "Epoch 22/100\n",
      "1871/1871 [==============================] - 36s 19ms/step - loss: 4.3553 - accuracy: 0.1927\n",
      "Epoch 23/100\n",
      "1871/1871 [==============================] - 32s 17ms/step - loss: 4.3346 - accuracy: 0.1930\n",
      "Epoch 24/100\n",
      "1871/1871 [==============================] - 31s 17ms/step - loss: 4.3135 - accuracy: 0.1956\n",
      "Epoch 25/100\n",
      "1871/1871 [==============================] - 38s 20ms/step - loss: 4.2935 - accuracy: 0.1954\n",
      "Epoch 26/100\n",
      "1871/1871 [==============================] - 56s 30ms/step - loss: 4.2755 - accuracy: 0.1972\n",
      "Epoch 27/100\n",
      "1871/1871 [==============================] - 48s 25ms/step - loss: 4.2577 - accuracy: 0.1978\n",
      "Epoch 28/100\n",
      "1871/1871 [==============================] - 46s 24ms/step - loss: 4.2410 - accuracy: 0.1976\n",
      "Epoch 29/100\n",
      "1871/1871 [==============================] - 42s 22ms/step - loss: 4.2245 - accuracy: 0.1980\n",
      "Epoch 30/100\n",
      "1871/1871 [==============================] - 44s 24ms/step - loss: 4.2079 - accuracy: 0.1988\n",
      "Epoch 31/100\n",
      "1871/1871 [==============================] - 58s 31ms/step - loss: 4.1941 - accuracy: 0.1997\n",
      "Epoch 32/100\n",
      "1871/1871 [==============================] - 42s 22ms/step - loss: 4.1796 - accuracy: 0.1998\n",
      "Epoch 33/100\n",
      "1871/1871 [==============================] - 38s 20ms/step - loss: 4.1662 - accuracy: 0.2003\n",
      "Epoch 34/100\n",
      "1871/1871 [==============================] - 44s 23ms/step - loss: 4.1535 - accuracy: 0.1998\n",
      "Epoch 35/100\n",
      "1871/1871 [==============================] - 36s 19ms/step - loss: 4.1407 - accuracy: 0.1999\n",
      "Epoch 36/100\n",
      "1871/1871 [==============================] - 30s 16ms/step - loss: 4.1290 - accuracy: 0.2012\n",
      "Epoch 37/100\n",
      "1871/1871 [==============================] - 30s 16ms/step - loss: 4.1177 - accuracy: 0.2014\n",
      "Epoch 38/100\n",
      "1871/1871 [==============================] - 29s 16ms/step - loss: 4.1069 - accuracy: 0.2016\n",
      "Epoch 39/100\n",
      "1871/1871 [==============================] - 37s 20ms/step - loss: 4.0958 - accuracy: 0.2017\n",
      "Epoch 40/100\n",
      "1871/1871 [==============================] - 44s 24ms/step - loss: 4.0865 - accuracy: 0.2023\n",
      "Epoch 41/100\n",
      "1871/1871 [==============================] - 37s 20ms/step - loss: 4.0772 - accuracy: 0.2025\n",
      "Epoch 42/100\n",
      "1871/1871 [==============================] - 33s 18ms/step - loss: 4.0673 - accuracy: 0.2019\n",
      "Epoch 43/100\n",
      "1871/1871 [==============================] - 33s 17ms/step - loss: 4.0593 - accuracy: 0.2018\n",
      "Epoch 44/100\n",
      "1871/1871 [==============================] - 33s 18ms/step - loss: 4.0511 - accuracy: 0.2023\n",
      "Epoch 45/100\n",
      "1871/1871 [==============================] - 33s 17ms/step - loss: 4.0423 - accuracy: 0.2028\n",
      "Epoch 46/100\n",
      "1871/1871 [==============================] - 34s 18ms/step - loss: 4.0347 - accuracy: 0.2020\n",
      "Epoch 47/100\n",
      "1871/1871 [==============================] - 33s 17ms/step - loss: 4.0277 - accuracy: 0.2029\n",
      "Epoch 48/100\n",
      "1871/1871 [==============================] - 42s 23ms/step - loss: 4.0206 - accuracy: 0.2023\n",
      "Epoch 49/100\n",
      "1871/1871 [==============================] - 38s 20ms/step - loss: 4.0130 - accuracy: 0.2031\n",
      "Epoch 50/100\n",
      "1871/1871 [==============================] - 35s 19ms/step - loss: 4.0075 - accuracy: 0.2029\n",
      "Epoch 51/100\n",
      "1871/1871 [==============================] - 33s 18ms/step - loss: 4.0009 - accuracy: 0.2028\n",
      "Epoch 52/100\n",
      "1871/1871 [==============================] - 41s 22ms/step - loss: 3.9947 - accuracy: 0.2034\n",
      "Epoch 53/100\n",
      "1871/1871 [==============================] - 34s 18ms/step - loss: 3.9896 - accuracy: 0.2033\n",
      "Epoch 54/100\n",
      "1871/1871 [==============================] - 33s 18ms/step - loss: 3.9838 - accuracy: 0.2026\n",
      "Epoch 55/100\n",
      "1871/1871 [==============================] - 36s 19ms/step - loss: 3.9777 - accuracy: 0.2021\n",
      "Epoch 56/100\n",
      "1871/1871 [==============================] - 35s 19ms/step - loss: 3.9727 - accuracy: 0.2020\n",
      "Epoch 57/100\n",
      "1871/1871 [==============================] - 37s 20ms/step - loss: 3.9680 - accuracy: 0.2028\n",
      "Epoch 58/100\n",
      "1871/1871 [==============================] - 36s 19ms/step - loss: 3.9630 - accuracy: 0.2040\n",
      "Epoch 59/100\n",
      "1871/1871 [==============================] - 37s 20ms/step - loss: 3.9575 - accuracy: 0.2024\n",
      "Epoch 60/100\n",
      "1871/1871 [==============================] - 37s 20ms/step - loss: 3.9535 - accuracy: 0.2031\n",
      "Epoch 61/100\n",
      "1871/1871 [==============================] - 40s 21ms/step - loss: 3.9501 - accuracy: 0.2025\n",
      "Epoch 62/100\n",
      "1871/1871 [==============================] - 47s 25ms/step - loss: 3.9447 - accuracy: 0.2025\n",
      "Epoch 63/100\n",
      "1871/1871 [==============================] - 40s 21ms/step - loss: 3.9404 - accuracy: 0.2028\n",
      "Epoch 64/100\n",
      "1871/1871 [==============================] - 41s 22ms/step - loss: 3.9371 - accuracy: 0.2031\n",
      "Epoch 65/100\n",
      "1871/1871 [==============================] - 45s 24ms/step - loss: 3.9332 - accuracy: 0.2027\n",
      "Epoch 66/100\n",
      "1871/1871 [==============================] - 45s 24ms/step - loss: 3.9293 - accuracy: 0.2036\n",
      "Epoch 67/100\n",
      "1871/1871 [==============================] - 44s 23ms/step - loss: 3.9261 - accuracy: 0.2027\n",
      "Epoch 68/100\n",
      "1871/1871 [==============================] - 43s 23ms/step - loss: 3.9220 - accuracy: 0.2031\n",
      "Epoch 69/100\n",
      "1871/1871 [==============================] - 43s 23ms/step - loss: 3.9188 - accuracy: 0.2023\n",
      "Epoch 70/100\n",
      "1871/1871 [==============================] - 42s 22ms/step - loss: 3.9163 - accuracy: 0.2026\n",
      "Epoch 71/100\n",
      "1871/1871 [==============================] - 50s 27ms/step - loss: 3.9124 - accuracy: 0.2035\n",
      "Epoch 72/100\n",
      "1871/1871 [==============================] - 35s 19ms/step - loss: 3.9089 - accuracy: 0.2023\n",
      "Epoch 73/100\n",
      "1871/1871 [==============================] - 31s 16ms/step - loss: 3.9062 - accuracy: 0.2016\n",
      "Epoch 74/100\n",
      "1871/1871 [==============================] - 30s 16ms/step - loss: 3.9029 - accuracy: 0.2028\n",
      "Epoch 75/100\n",
      "1871/1871 [==============================] - 30s 16ms/step - loss: 3.9003 - accuracy: 0.2027\n",
      "Epoch 76/100\n",
      "1871/1871 [==============================] - 30s 16ms/step - loss: 3.8974 - accuracy: 0.2029\n",
      "Epoch 77/100\n",
      "1871/1871 [==============================] - 30s 16ms/step - loss: 3.8953 - accuracy: 0.2029\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1871/1871 [==============================] - 30s 16ms/step - loss: 3.8923 - accuracy: 0.2013\n",
      "Epoch 79/100\n",
      "1871/1871 [==============================] - 34s 18ms/step - loss: 3.8899 - accuracy: 0.2022\n",
      "Epoch 80/100\n",
      "1871/1871 [==============================] - 57613s 31s/step - loss: 3.8871 - accuracy: 0.2029\n",
      "Epoch 81/100\n",
      "1871/1871 [==============================] - 37s 20ms/step - loss: 3.8847 - accuracy: 0.2016\n",
      "Epoch 82/100\n",
      "1871/1871 [==============================] - 42s 23ms/step - loss: 3.8824 - accuracy: 0.2021\n",
      "Epoch 83/100\n",
      "1871/1871 [==============================] - 46s 25ms/step - loss: 3.8804 - accuracy: 0.2025\n",
      "Epoch 84/100\n",
      "1871/1871 [==============================] - 45s 24ms/step - loss: 3.8774 - accuracy: 0.2023\n",
      "Epoch 85/100\n",
      "1871/1871 [==============================] - 43s 23ms/step - loss: 3.8753 - accuracy: 0.2032\n",
      "Epoch 86/100\n",
      "1871/1871 [==============================] - 43s 23ms/step - loss: 3.8735 - accuracy: 0.2025\n",
      "Epoch 87/100\n",
      "1871/1871 [==============================] - 44s 24ms/step - loss: 3.8711 - accuracy: 0.2031\n",
      "Epoch 88/100\n",
      "1871/1871 [==============================] - 49s 26ms/step - loss: 3.8692 - accuracy: 0.2029\n",
      "Epoch 89/100\n",
      "1871/1871 [==============================] - 55s 29ms/step - loss: 3.8679 - accuracy: 0.2026\n",
      "Epoch 90/100\n",
      "1871/1871 [==============================] - 52s 28ms/step - loss: 3.8656 - accuracy: 0.2017\n",
      "Epoch 91/100\n",
      "1871/1871 [==============================] - 53s 28ms/step - loss: 3.8637 - accuracy: 0.2024\n",
      "Epoch 92/100\n",
      "1871/1871 [==============================] - 54s 29ms/step - loss: 3.8614 - accuracy: 0.2016\n",
      "Epoch 93/100\n",
      "1871/1871 [==============================] - 56s 30ms/step - loss: 3.8596 - accuracy: 0.2029\n",
      "Epoch 94/100\n",
      "1871/1871 [==============================] - 66s 36ms/step - loss: 3.8584 - accuracy: 0.2012\n",
      "Epoch 95/100\n",
      "1871/1871 [==============================] - 59s 31ms/step - loss: 3.8567 - accuracy: 0.2018\n",
      "Epoch 96/100\n",
      "1871/1871 [==============================] - 51s 27ms/step - loss: 3.8545 - accuracy: 0.2010\n",
      "Epoch 97/100\n",
      "1871/1871 [==============================] - 47s 25ms/step - loss: 3.8532 - accuracy: 0.2019\n",
      "Epoch 98/100\n",
      "1871/1871 [==============================] - 48s 26ms/step - loss: 3.8515 - accuracy: 0.2013\n",
      "Epoch 99/100\n",
      "1871/1871 [==============================] - 48s 26ms/step - loss: 3.8500 - accuracy: 0.2020\n",
      "Epoch 100/100\n",
      "1871/1871 [==============================] - 54s 29ms/step - loss: 3.8487 - accuracy: 0.2015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20893b73e50>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_set, y_set, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a881e67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, tokenizer, word, times):\n",
    "    in_text, out_text=word, word\n",
    "    \n",
    "    \n",
    "    for i in range(times):\n",
    "        encoded_word=tokenizer.texts_to_sequences([in_text])[0]\n",
    "        encoded_word=np.array(encoded_word)\n",
    "        \n",
    "        y_pred=model.predict_classes(encoded)\n",
    "        \n",
    "        \n",
    "        out_word=''\n",
    "        \n",
    "        for text_word, index in tokenizer.word_index.items():\n",
    "            if index== y_pred:\n",
    "                out_word=text_word\n",
    "                break\n",
    "        in_text=out_word\n",
    "        out_text=out_text+\" \"+out_word\n",
    "    return out_text\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e1f86d40",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [107]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProject\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Input \u001b[1;32mIn [106]\u001b[0m, in \u001b[0;36mgenerate\u001b[1;34m(model, tokenizer, word, times)\u001b[0m\n\u001b[0;32m      6\u001b[0m encoded_word\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mtexts_to_sequences([in_text])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      7\u001b[0m encoded_word\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(encoded_word)\n\u001b[1;32m----> 9\u001b[0m y_pred\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_classes\u001b[49m(encoded)\n\u001b[0;32m     12\u001b[0m out_word\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text_word, index \u001b[38;5;129;01min\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mword_index\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "print(generate(model, tokenizer,'Project' , 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191dbfaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
